{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37746bd1-3e1c-4ac2-b250-5b53e4f3bea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: konlpy in c:\\users\\kosa\\anaconda3\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in c:\\users\\kosa\\anaconda3\\lib\\site-packages (from konlpy) (1.5.0)\n",
      "Requirement already satisfied: lxml>=4.1.0 in c:\\users\\kosa\\anaconda3\\lib\\site-packages (from konlpy) (4.9.3)\n",
      "Requirement already satisfied: numpy>=1.6 in c:\\users\\kosa\\anaconda3\\lib\\site-packages (from konlpy) (1.24.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\kosa\\anaconda3\\lib\\site-packages (from JPype1>=0.7.0->konlpy) (23.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df93d16e-3d8f-4c0c-912f-88249cfac30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "from transformers import BertTokenizer, BertModel, RobertaTokenizer, RobertaModel\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from safetensors.torch import load_file\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c67d0bc-2a20-4d62-993d-51ea99ea4c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('law_data_3.csv')\n",
    "df1 = pd.read_csv('law_data_2.csv')\n",
    "df2 = pd.read_csv('law_data_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d336b808-48ac-405d-8b84-f6851d2683cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b8a2ac0-2412-4862-86d8-6f0e291918c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['전문'] = df['전문'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea1c5537-d487-47dd-8fa6-29ea3616857f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a04f94b-dff9-410c-a671-30b88ade500e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dddd39711b1a4dd39c3f29cb221890db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/599 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KOSA\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\KOSA\\.cache\\huggingface\\hub\\models--BM-K--KoSimCSE-roberta-multitask. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9c36838552d4840a369b37affcd8b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae12f3cb2c0c4554b87abf6d5c8c61f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/752k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab17415e1b14eebadb97eb5029d33f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/156 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71d0533e3a2a40e1a0995cb2f429a61b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/764 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a83f1e0d6e94a3887c6322254f3d58a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/442M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"BM-K/KoSimCSE-roberta-multitask\")\n",
    "model = AutoModel.from_pretrained(\"BM-K/KoSimCSE-roberta-multitask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0504ef82-1670-4aed-8e5e-2b0c81fe62cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ec4fcfa-f589-4fb1-8306-f51619e954b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'[^\\w\\s가-힣]', '', text)\n",
    "    text = text.lower()\n",
    "    text = ' '.join(okt.morphs(text))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ac00220-8684-41d6-9942-c9d7d0d178a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, chunk_size=128, overlap=32):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), chunk_size - overlap):\n",
    "        chunk = ' '.join(words[i:i + chunk_size])\n",
    "        chunks.append(chunk)\n",
    "        if i + chunk_size >= len(words):\n",
    "            break\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c61d4c09-c831-4200-8a41-f8c5ad781c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    cls_embedding = outputs.last_hidden_state.mean(dim=1).squeeze()\n",
    "    return cls_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1d1108-f8cc-4cea-9dab-dd8ea8b03d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed_text'] = df['전문'].apply(preprocess_text)\n",
    "df['chunks'] = df['processed_text'].apply(lambda x: chunk_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3e3171-48e7-4ca7-8807-ac6090cec15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_embeddings = []\n",
    "chunk_to_doc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0220630d-8715-49ff-9adf-90a3ffff984f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, chunks in enumerate(df['chunks']):\n",
    "    for chunk in chunks:\n",
    "        chunk_embedding = encode_text(chunk)\n",
    "        chunk_embeddings.append(chunk_embedding)\n",
    "        chunk_to_doc.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c88b31-6219-40f9-9327-980d7256201d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_embeddings = torch.stack(chunk_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8457720-a84e-487d-b512-ddaa54e09536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_path = '/content/drive/My Drive/content/chunk_embeddings.pt'\n",
    "# torch.save({\n",
    "#     'chunk_embeddings': chunk_embeddings,\n",
    "#     'chunk_to_doc': chunk_to_doc\n",
    "# }, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "384d0d5c-c3e3-44e4-8d77-3c17623f5362",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'chunk_embeddings.pt'\n",
    "checkpoint = torch.load(save_path)\n",
    "chunk_embeddings = checkpoint['chunk_embeddings']\n",
    "chunk_to_doc = checkpoint['chunk_to_doc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7f3b30a-c2eb-4988-bb3c-75ff80ef540e",
   "metadata": {},
   "outputs": [],
   "source": [
    "  def search_query(query, df, chunk_embeddings, chunk_to_doc, top_k=5):\n",
    "    query = preprocess_text(query)\n",
    "    query_embedding = encode_text(query).unsqueeze(0).to(device)\n",
    "\n",
    "    query_embedding_cpu = query_embedding.cpu()\n",
    "    chunk_embeddings_cpu = chunk_embeddings.cpu()\n",
    "\n",
    "    similarities = cosine_similarity(query_embedding_cpu, chunk_embeddings_cpu).flatten()\n",
    "\n",
    "    top_indices = similarities.argsort()[-top_k:][::-1]\n",
    "\n",
    "    search_results = df.iloc[[chunk_to_doc[i] for i in top_indices]]\n",
    "    return search_results[['주문']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e060c66-a237-4286-af66-acd0a4838287",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"내에서 피해자 D(남, 63세)과 함께 술을 마시던 중 욕설 등 말다툼 중에 화가 나 그곳에 있던 위험한 물건인 과도(칼날 길이 약 9cm, 전체 길이 약 19.5cm)를 집어 들고 피해자의 좌측 가슴 부위를 1회 찔러 피해자에게 약 2주간의 치료를 요하는 흉부의 상세불명 부분의 열린상처 등 상해를 가하였다\"\n",
    "#query = '고양시 일산동구 B에 있는 C 1층에 있는 피해자 D가 운영하는 E에서, 계산대에 올려 놓은 우유 2팩을 바닥으로 던져 우유가 쏟아지게 하고, 소리를 지르는 등 소란을 피워 위력으로써 피해자의 제과점 운영 업무를 방해하였다'\n",
    "#query = '음주운전을 하여 행인 2명을 부상시키고 후속 처리를 하지 않고 도망쳤다. 동일 전과가 이전에 있다'\n",
    "#query = '보일러의 설치상 하자 등을 발견할 것을 기대할 수도 없다'\n",
    "#query = ' 이러한 경우 자동차의 운전업무에 종사하는 사람에게는 전방 교통상황을 잘 보고 조향 및 제동 장치 등을 정확히 조작하는 등 안전하게 운전하여 사고를 미리 방지하여야 할업무상 주의의무가 있다'\n",
    "search_result = search_query(query, df, chunk_embeddings, chunk_to_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4104529b-40bc-4197-b755-114f8112fdfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     주문\n",
      "1840  피고인을 징역 1년에 처한다. 다만, 이 판결 확정일부터 3년간 위 형의 집행을 유...\n",
      "1499  피고인을 징역 1년에 처한다. 다만, 이 판결 확정일부터 2년간 위 형의 집행을 유...\n",
      "1402  피고인을 징역 6월에 처한다. 다만, 이 판결 확정일부터 2년간 위 형의 집행을 유...\n",
      "1848  피고인을 징역 1년에 처한다. 다만, 이 판결 확정일부터 2년간 위 형의 집행을 유...\n",
      "1145           피고인을 징역 6년에 처한다. 압수된 식칼 1개(증 제1호)를 몰수한다.\n"
     ]
    }
   ],
   "source": [
    "print(search_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40649f9d-0ed2-42a4-9937-908c798c783c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc460ea9-4e0f-4f74-93a0-28aafb66e096",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "gen_model_path = 'beomi-Llama-3-KoEn-8B-Instruct-preview'\n",
    "gen_tokenizer = AutoTokenizer.from_pretrained(gen_model_path)\n",
    "gen_model = AutoModelForCausalLM.from_pretrained(gen_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a738eb05-e2e9-4b11-a88c-753f13bc480a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77daf15-ab44-47f9-a366-538a641a7245",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
