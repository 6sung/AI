{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5eb90405-8a8b-4c3d-99b1-e5b5ab003e28",
   "metadata": {},
   "source": [
    "VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e83e7d66-04eb-4b85-aac2-4855dbc45e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1) float32 (10000, 28, 28, 1) float32\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "(X_train, _), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "def preprocess_data(dataset):\n",
    "    dataset = dataset.astype('float32') / 255.0\n",
    "    dataset = np.expand_dims(dataset, -1)\n",
    "    return dataset\n",
    "\n",
    "X_train = preprocess_data(X_train)\n",
    "X_test = preprocess_data(X_test)\n",
    "\n",
    "print(X_train.shape, X_train.dtype, X_test.shape, X_test.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c673d30-63c1-41d7-84a0-5ef548686a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE Encoder\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def vae_encoder(latent_dim=2, shape=(28,28,1)):\n",
    "    inputs = layers.Input(shape=shape)\n",
    "    x = layers.Conv2D(32, 3, activation='relu', strides=2, padding='same')(inputs)\n",
    "    x = layers.Conv2D(64, 3, activation='relu', strides=2, padding='same')(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(16, activation='relu')(x)\n",
    "    \n",
    "    z_mean = layers.Dense(latent_dim)(x)\n",
    "    z_log_var = layers.Dense(latent_dim)(x)\n",
    "    model = Model(inputs, [z_mean, z_log_var], name='encoder')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2d53912-5400-4236-bfaf-a6bf2d1de187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE Decoder\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def vae_decoder(latent_dim=2):\n",
    "    latent_inputs = layers.Input(shape=(latent_dim,))\n",
    "    x = layers.Dense(7*7*64, activation='relu')(latent_inputs)\n",
    "    \n",
    "    x = layers.Reshape(target_shape=(7,7,64))(x)\n",
    "    x = layers.Conv2DTranspose(64, 3, activation='relu', strides=2, padding='same')(x)\n",
    "    \n",
    "    x = layers.Conv2DTranspose(32, 3, activation='relu', strides=2, padding='same')(x)\n",
    "    \n",
    "    outputs = layers.Conv2DTranspose(1, 3, activation='sigmoid', padding='same')(x)\n",
    "    \n",
    "    model = Model(latent_inputs, outputs, name='decoder')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec99993a-cd1a-422e-824b-ad179604c364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def sampling(z_mean, z_log_var):\n",
    "    batch = tf.shape(z_mean)[0]\n",
    "    dim = tf.shape(z_mean)[1]\n",
    "    epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b5c3632-6daa-4fa0-aca4-3b73b86bff05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)        [(None, 28, 28, 1)]          0         []                            \n",
      "                                                                                                  \n",
      " encoder (Functional)        [(None, 2),                  69076     ['input_3[0][0]']             \n",
      "                              (None, 2)]                                                          \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape (TFOpLa  (2,)                         0         ['encoder[0][0]']             \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_1 (TFOp  (2,)                         0         ['encoder[0][0]']             \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLamb  (None, 2)                    0         ['encoder[0][1]']             \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (  ()                           0         ['tf.compat.v1.shape[0][0]']  \n",
      " SlicingOpLambda)                                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  ()                           0         ['tf.compat.v1.shape_1[0][0]']\n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " tf.math.exp (TFOpLambda)    (None, 2)                    0         ['tf.math.multiply[0][0]']    \n",
      "                                                                                                  \n",
      " tf.random.normal (TFOpLamb  (None, 2)                    0         ['tf.__operators__.getitem[0][\n",
      " da)                                                                0]',                          \n",
      "                                                                     'tf.__operators__.getitem_1[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " tf.math.multiply_1 (TFOpLa  (None, 2)                    0         ['tf.math.exp[0][0]',         \n",
      " mbda)                                                               'tf.random.normal[0][0]']    \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOp  (None, 2)                    0         ['encoder[0][0]',             \n",
      " Lambda)                                                             'tf.math.multiply_1[0][0]']  \n",
      "                                                                                                  \n",
      " decoder (Functional)        (None, 28, 28, 1)            65089     ['tf.__operators__.add[0][0]']\n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 134165 (524.08 KB)\n",
      "Trainable params: 134165 (524.08 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 2\n",
    "encoder = vae_encoder(latent_dim=latent_dim)\n",
    "decoder = vae_decoder(latent_dim=latent_dim)\n",
    "inputs = layers.Input(shape=(28,28,1))\n",
    "z_mean, z_log_var = encoder(inputs)\n",
    "z = sampling(z_mean, z_log_var)\n",
    "outputs = decoder(z)\n",
    "vae_model = Model(inputs, outputs)\n",
    "vae_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be06baad-034a-4066-8d25-6ad138d4896b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import mse\n",
    "# 재구성 손실 + KL 손실\n",
    "def vae_loss(inputs, outputs, z_mean, z_log_var):\n",
    "# 재구성 손실\n",
    "    reconstruction_loss = mse(tf.keras.backend.flatten(inputs), tf.keras.backend.flatten(outputs))\n",
    "    reconstruction_loss *= 28*28\n",
    "    # KL 발산 손실\n",
    "    kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
    "    kl_loss = tf.reduce_sum(kl_loss, axis=-1)\n",
    "    kl_loss *= -0.5\n",
    "    total_loss = tf.reduce_mean(reconstruction_loss + kl_loss)\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4149c398-149b-4ffa-939d-56a8761b77af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "469/469 [==============================] - 26s 53ms/step - loss: 55.5053 - val_loss: 48.4625\n",
      "Epoch 2/50\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 45.3740 - val_loss: 43.1519\n",
      "Epoch 3/50\n",
      "469/469 [==============================] - 24s 50ms/step - loss: 41.8618 - val_loss: 41.2535\n",
      "Epoch 4/50\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 40.6309 - val_loss: 40.2729\n",
      "Epoch 5/50\n",
      "469/469 [==============================] - 24s 50ms/step - loss: 39.9954 - val_loss: 39.7570\n",
      "Epoch 6/50\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 39.5789 - val_loss: 39.5161\n",
      "Epoch 7/50\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 39.2728 - val_loss: 39.5852\n",
      "Epoch 8/50\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 39.0427 - val_loss: 39.0450\n",
      "Epoch 9/50\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 38.8311 - val_loss: 38.9060\n",
      "Epoch 10/50\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 38.6992 - val_loss: 38.7059\n",
      "Epoch 11/50\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 38.4948 - val_loss: 38.5713\n",
      "Epoch 12/50\n",
      "469/469 [==============================] - 24s 52ms/step - loss: 38.4251 - val_loss: 38.6674\n",
      "Epoch 13/50\n",
      "469/469 [==============================] - 25s 53ms/step - loss: 38.3065 - val_loss: 38.3931\n",
      "Epoch 14/50\n",
      "469/469 [==============================] - 25s 53ms/step - loss: 38.2097 - val_loss: 38.4279\n",
      "Epoch 15/50\n",
      "469/469 [==============================] - 25s 54ms/step - loss: 38.1214 - val_loss: 38.2118\n",
      "Epoch 16/50\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 38.0638 - val_loss: 38.1898\n",
      "Epoch 17/50\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 37.9697 - val_loss: 38.3230\n",
      "Epoch 18/50\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 37.9031 - val_loss: 38.1776\n",
      "Epoch 19/50\n",
      "469/469 [==============================] - 24s 50ms/step - loss: 37.8243 - val_loss: 38.1202\n",
      "Epoch 20/50\n",
      "469/469 [==============================] - 24s 50ms/step - loss: 37.7985 - val_loss: 38.0835\n",
      "Epoch 21/50\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 37.7266 - val_loss: 37.9354\n",
      "Epoch 22/50\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 37.6813 - val_loss: 37.9782\n",
      "Epoch 23/50\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 37.6320 - val_loss: 37.9416\n",
      "Epoch 24/50\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 37.5581 - val_loss: 38.0382\n",
      "Epoch 25/50\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 37.5377 - val_loss: 37.8506\n",
      "Epoch 26/50\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 37.5227 - val_loss: 37.8758\n",
      "Epoch 27/50\n",
      "469/469 [==============================] - 24s 50ms/step - loss: 37.4372 - val_loss: 37.7496\n",
      "Epoch 28/50\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 37.4244 - val_loss: 37.8486\n",
      "Epoch 29/50\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 37.3778 - val_loss: 37.9842\n",
      "Epoch 30/50\n",
      "469/469 [==============================] - 23s 49ms/step - loss: 37.3418 - val_loss: 38.0426\n",
      "Epoch 31/50\n",
      "469/469 [==============================] - 24s 50ms/step - loss: 37.3162 - val_loss: 37.7428\n",
      "Epoch 32/50\n",
      "469/469 [==============================] - 24s 50ms/step - loss: 37.3081 - val_loss: 37.7166\n",
      "Epoch 33/50\n",
      "469/469 [==============================] - 24s 50ms/step - loss: 37.2871 - val_loss: 37.8415\n",
      "Epoch 34/50\n",
      "469/469 [==============================] - 24s 50ms/step - loss: 37.2335 - val_loss: 37.6953\n",
      "Epoch 35/50\n",
      "469/469 [==============================] - 24s 50ms/step - loss: 37.2119 - val_loss: 37.7494\n",
      "Epoch 36/50\n",
      "469/469 [==============================] - 24s 50ms/step - loss: 37.1730 - val_loss: 37.6408\n",
      "Epoch 37/50\n",
      "469/469 [==============================] - 24s 50ms/step - loss: 37.1644 - val_loss: 37.6644\n",
      "Epoch 38/50\n",
      "469/469 [==============================] - 24s 50ms/step - loss: 37.1338 - val_loss: 37.6916\n",
      "Epoch 39/50\n",
      "469/469 [==============================] - 24s 50ms/step - loss: 37.1277 - val_loss: 37.5973\n",
      "Epoch 40/50\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 37.1088 - val_loss: 37.6786\n",
      "Epoch 41/50\n",
      "469/469 [==============================] - 23s 50ms/step - loss: 37.0604 - val_loss: 37.6728\n",
      "Epoch 42/50\n",
      "469/469 [==============================] - 23s 49ms/step - loss: 37.0320 - val_loss: 37.5677\n",
      "Epoch 43/50\n",
      "469/469 [==============================] - 23s 50ms/step - loss: 37.0197 - val_loss: 37.6696\n",
      "Epoch 44/50\n",
      "469/469 [==============================] - 23s 49ms/step - loss: 36.9913 - val_loss: 37.5774\n",
      "Epoch 45/50\n",
      "469/469 [==============================] - 23s 50ms/step - loss: 36.9900 - val_loss: 37.5260\n",
      "Epoch 46/50\n",
      "469/469 [==============================] - 23s 49ms/step - loss: 36.9723 - val_loss: 37.5362\n",
      "Epoch 47/50\n",
      "469/469 [==============================] - 23s 50ms/step - loss: 36.9354 - val_loss: 37.6005\n",
      "Epoch 48/50\n",
      "469/469 [==============================] - 24s 50ms/step - loss: 36.9390 - val_loss: 37.7476\n",
      "Epoch 49/50\n",
      "469/469 [==============================] - 24s 52ms/step - loss: 36.9090 - val_loss: 37.6340\n",
      "Epoch 50/50\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 36.9033 - val_loss: 37.5478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x185b1d512d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae_model.add_loss(vae_loss(inputs, outputs, z_mean, z_log_var))\n",
    "vae_model.compile(optimizer='adam')\n",
    "vae_model.fit(X_train, epochs=50, batch_size=128, validation_data=(X_test, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7473b59b-590a-417f-b9ba-52abc75f2249",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvae.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save(\"vae.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e78a9a-36c1-43ae-9743-f80f16ea871f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_model.load_weights(\"vae.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e22792-04e9-4b6c-8192-8d20e7e18044",
   "metadata": {},
   "outputs": [],
   "source": [
    "digit = decoder.predict([[0, 0]])\n",
    "print(digit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7631b475-a557-4931-a04c-d1a129a32e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(digit[0,...], cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ab3d1e-386d-438d-9691-15eba60d67ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_test_mean, z_test_log_var = np.array(encoder.predict(X_test[:16,...]))\n",
    "digits = decoder.predict(sampling(z_test_mean, z_test_log_var))\n",
    "\n",
    "plt.figure(figsize=(2,2))\n",
    "for i in range(16):\n",
    "    plt.subplot(4, 4, i+1)\n",
    "    plt.imshow(digits[i,...], cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(y_test[:16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfb9ae0-cd0c-4d96-a9f8-211865bfcda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_latent1, x_test_latent2 = np.array(encoder.predict(X_test))\n",
    "x_test_mean, x_test_log_var = x_test_latent1[:,0], x_test_latent1[:,1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.14",
   "language": "python",
   "name": "tf2.14"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
