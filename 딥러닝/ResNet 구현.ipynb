{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "272851b3-1da3-411e-98c2-1d6e3d4eab6d",
   "metadata": {},
   "source": [
    "CIFAR-10 이미지 분류를 위한 ResNet 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e2bf7ca-824f-482d-be30-8f1ef417230c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import AveragePooling2D, Flatten\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6fb754a-0c2d-4b31-9ddc-863f215e6768",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cf50b7d-ccf8-4558-a8be-26558ad1cccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X shape :  (50000, 32, 32, 3)\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "(train_X, train_y), (test_X, test_y) = cifar10.load_data()\n",
    "print(\"train_X shape : \", train_X.shape)\n",
    "print(test_X.shape[0],\"test samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f407d920-d04b-4e1e-b59a-5dfa30089c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = train_X.shape[1:]\n",
    "\n",
    "train_X = train_X / 255.0\n",
    "test_X = test_X / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b55b3860-21dd-4982-bf82-2aed51941359",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05e55d6e-65c4-4114-a9aa-2dcc12832641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 32, 32, 32)           896       ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 32, 32, 32)           128       ['conv2d[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 32)           9248      ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 32, 32, 32)           128       ['conv2d_1[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " add (Add)                   (None, 32, 32, 32)           0         ['batch_normalization[0][0]', \n",
      "                                                                     'batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " activation (Activation)     (None, 32, 32, 32)           0         ['add[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 32, 32, 32)           9248      ['activation[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 32, 32, 32)           128       ['conv2d_2[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 32, 32, 32)           9248      ['batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 32, 32, 32)           128       ['conv2d_3[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " add_1 (Add)                 (None, 32, 32, 32)           0         ['activation[0][0]',          \n",
      "                                                                     'batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " activation_1 (Activation)   (None, 32, 32, 32)           0         ['add_1[0][0]']               \n",
      "                                                                                                  \n",
      " average_pooling2d (Average  (None, 4, 4, 32)             0         ['activation_1[0][0]']        \n",
      " Pooling2D)                                                                                       \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 512)                  0         ['average_pooling2d[0][0]']   \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 512)                  262656    ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 10)                   5130      ['dense[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 296938 (1.13 MB)\n",
      "Trainable params: 296682 (1.13 MB)\n",
      "Non-trainable params: 256 (1.00 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv = Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\")\n",
    "x = conv(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "conv = Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\", kernel_regularizer=l2(1e-4))\n",
    "y = conv(x)\n",
    "y = BatchNormalization()(y)\n",
    "\n",
    "x = keras.layers.add([x,y])\n",
    "x = Activation(\"relu\")(x)\n",
    "\n",
    "conv = Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\", kernel_regularizer=l2(1e-4))\n",
    "y = conv(x)\n",
    "y = BatchNormalization()(y)\n",
    "\n",
    "conv = Conv2D(filters=32, kernel_size=3, padding=\"same\", kernel_regularizer=l2(1e-4))\n",
    "y = conv(y)\n",
    "y = BatchNormalization()(y)\n",
    "\n",
    "x = keras.layers.add([x,y])\n",
    "x = Activation(\"relu\")(x)\n",
    "\n",
    "x = AveragePooling2D(pool_size=8)(x)\n",
    "y = Flatten()(x)\n",
    "\n",
    "y = Dense(512, activation=\"relu\")(y)\n",
    "outputs = Dense(NUM_CLASSES, activation=\"softmax\")(y)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0138415d-65a1-49fa-97d5-3671e0d1e795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 200\n",
    "save_dir = os.path.join(os.getcwd(), \"saved_models\")\n",
    "model_name = \"cifar10_model-{epoch:03d}-{val_accuracy:.4f}.h5\"\n",
    "\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor=\"val_accuracy\", save_best_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e234bf75-dc16-41ef-b6e2-e755467bc569",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    lr = 1e-3\n",
    "    if epoch > 90:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 60:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 40:\n",
    "        lr *= 1e-1\n",
    "    print(\"Learning rate : \", lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "129149aa-677b-42b7-9666-ebd92ca8384a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate :  0.001\n",
      "Epoch 1/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.3695 - accuracy: 0.5141\n",
      "Epoch 1: val_accuracy improved from -inf to 0.10020, saving model to C:\\Users\\KOSA\\AI\\saved_models\\cifar10_model-001-0.1002.h5\n",
      "250/250 [==============================] - 98s 384ms/step - loss: 1.3695 - accuracy: 0.5141 - val_loss: 3.4284 - val_accuracy: 0.1002 - lr: 0.0010\n",
      "Learning rate :  0.001\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KOSA\\anaconda3\\envs\\tf2.14\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - ETA: 0s - loss: 0.9812 - accuracy: 0.6566\n",
      "Epoch 2: val_accuracy improved from 0.10020 to 0.54510, saving model to C:\\Users\\KOSA\\AI\\saved_models\\cifar10_model-002-0.5451.h5\n",
      "250/250 [==============================] - 100s 400ms/step - loss: 0.9812 - accuracy: 0.6566 - val_loss: 1.2762 - val_accuracy: 0.5451 - lr: 0.0010\n",
      "Learning rate :  0.001\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.8493 - accuracy: 0.7061\n",
      "Epoch 3: val_accuracy improved from 0.54510 to 0.66490, saving model to C:\\Users\\KOSA\\AI\\saved_models\\cifar10_model-003-0.6649.h5\n",
      "250/250 [==============================] - 97s 388ms/step - loss: 0.8493 - accuracy: 0.7061 - val_loss: 0.9698 - val_accuracy: 0.6649 - lr: 0.0010\n",
      "Learning rate :  0.001\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.7631 - accuracy: 0.7358\n",
      "Epoch 4: val_accuracy improved from 0.66490 to 0.70810, saving model to C:\\Users\\KOSA\\AI\\saved_models\\cifar10_model-004-0.7081.h5\n",
      "250/250 [==============================] - 96s 383ms/step - loss: 0.7631 - accuracy: 0.7358 - val_loss: 0.8641 - val_accuracy: 0.7081 - lr: 0.0010\n",
      "Learning rate :  0.001\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6901 - accuracy: 0.7632\n",
      "Epoch 5: val_accuracy improved from 0.70810 to 0.71190, saving model to C:\\Users\\KOSA\\AI\\saved_models\\cifar10_model-005-0.7119.h5\n",
      "250/250 [==============================] - 92s 370ms/step - loss: 0.6901 - accuracy: 0.7632 - val_loss: 0.8468 - val_accuracy: 0.7119 - lr: 0.0010\n",
      "Learning rate :  0.001\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6378 - accuracy: 0.7818\n",
      "Epoch 6: val_accuracy improved from 0.71190 to 0.74140, saving model to C:\\Users\\KOSA\\AI\\saved_models\\cifar10_model-006-0.7414.h5\n",
      "250/250 [==============================] - 92s 369ms/step - loss: 0.6378 - accuracy: 0.7818 - val_loss: 0.7729 - val_accuracy: 0.7414 - lr: 0.0010\n",
      "Learning rate :  0.001\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5923 - accuracy: 0.7984\n",
      "Epoch 7: val_accuracy improved from 0.74140 to 0.75660, saving model to C:\\Users\\KOSA\\AI\\saved_models\\cifar10_model-007-0.7566.h5\n",
      "250/250 [==============================] - 93s 373ms/step - loss: 0.5923 - accuracy: 0.7984 - val_loss: 0.7160 - val_accuracy: 0.7566 - lr: 0.0010\n",
      "Learning rate :  0.001\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5487 - accuracy: 0.8125\n",
      "Epoch 8: val_accuracy did not improve from 0.75660\n",
      "250/250 [==============================] - 91s 363ms/step - loss: 0.5487 - accuracy: 0.8125 - val_loss: 0.7683 - val_accuracy: 0.7403 - lr: 0.0010\n",
      "Learning rate :  0.001\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.5123 - accuracy: 0.8235\n",
      "Epoch 9: val_accuracy improved from 0.75660 to 0.76640, saving model to C:\\Users\\KOSA\\AI\\saved_models\\cifar10_model-009-0.7664.h5\n",
      "250/250 [==============================] - 90s 362ms/step - loss: 0.5123 - accuracy: 0.8235 - val_loss: 0.7112 - val_accuracy: 0.7664 - lr: 0.0010\n",
      "Learning rate :  0.001\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.4770 - accuracy: 0.8392\n",
      "Epoch 10: val_accuracy did not improve from 0.76640\n",
      "250/250 [==============================] - 90s 361ms/step - loss: 0.4770 - accuracy: 0.8392 - val_loss: 0.7738 - val_accuracy: 0.7447 - lr: 0.0010\n",
      "Learning rate :  0.001\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.4414 - accuracy: 0.8506\n",
      "Epoch 11: val_accuracy did not improve from 0.76640\n",
      "250/250 [==============================] - 90s 361ms/step - loss: 0.4414 - accuracy: 0.8506 - val_loss: 0.7406 - val_accuracy: 0.7466 - lr: 0.0010\n",
      "Learning rate :  0.001\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.4179 - accuracy: 0.8599\n",
      "Epoch 12: val_accuracy did not improve from 0.76640\n",
      "250/250 [==============================] - 91s 363ms/step - loss: 0.4179 - accuracy: 0.8599 - val_loss: 0.7249 - val_accuracy: 0.7623 - lr: 0.0010\n",
      "Learning rate :  0.001\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.3837 - accuracy: 0.8704\n",
      "Epoch 13: val_accuracy did not improve from 0.76640\n",
      "250/250 [==============================] - 91s 363ms/step - loss: 0.3837 - accuracy: 0.8704 - val_loss: 0.7543 - val_accuracy: 0.7544 - lr: 0.0010\n",
      "Learning rate :  0.001\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.3551 - accuracy: 0.8817\n",
      "Epoch 14: val_accuracy improved from 0.76640 to 0.78400, saving model to C:\\Users\\KOSA\\AI\\saved_models\\cifar10_model-014-0.7840.h5\n",
      "250/250 [==============================] - 92s 369ms/step - loss: 0.3551 - accuracy: 0.8817 - val_loss: 0.6675 - val_accuracy: 0.7840 - lr: 0.0010\n",
      "Learning rate :  0.001\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.3326 - accuracy: 0.8907\n",
      "Epoch 15: val_accuracy did not improve from 0.78400\n",
      "250/250 [==============================] - 93s 374ms/step - loss: 0.3326 - accuracy: 0.8907 - val_loss: 0.7483 - val_accuracy: 0.7633 - lr: 0.0010\n",
      "Learning rate :  0.001\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.3071 - accuracy: 0.8986\n",
      "Epoch 16: val_accuracy did not improve from 0.78400\n",
      "250/250 [==============================] - 93s 373ms/step - loss: 0.3071 - accuracy: 0.8986 - val_loss: 0.7316 - val_accuracy: 0.7756 - lr: 0.0010\n",
      "Learning rate :  0.001\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.2853 - accuracy: 0.9085\n",
      "Epoch 17: val_accuracy did not improve from 0.78400\n",
      "250/250 [==============================] - 95s 379ms/step - loss: 0.2853 - accuracy: 0.9085 - val_loss: 0.7434 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Learning rate :  0.001\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.2602 - accuracy: 0.9143\n",
      "Epoch 18: val_accuracy did not improve from 0.78400\n",
      "250/250 [==============================] - 95s 381ms/step - loss: 0.2602 - accuracy: 0.9143 - val_loss: 0.7604 - val_accuracy: 0.7805 - lr: 0.0010\n",
      "Learning rate :  0.001\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.2425 - accuracy: 0.9228\n",
      "Epoch 19: val_accuracy did not improve from 0.78400\n",
      "250/250 [==============================] - 95s 381ms/step - loss: 0.2425 - accuracy: 0.9228 - val_loss: 0.7902 - val_accuracy: 0.7736 - lr: 0.0010\n",
      "Learning rate :  0.001\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.2194 - accuracy: 0.9315\n",
      "Epoch 20: val_accuracy did not improve from 0.78400\n",
      "250/250 [==============================] - 96s 384ms/step - loss: 0.2194 - accuracy: 0.9315 - val_loss: 0.7739 - val_accuracy: 0.7787 - lr: 0.0010\n",
      "Learning rate :  0.001\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.2012 - accuracy: 0.9378\n",
      "Epoch 21: val_accuracy did not improve from 0.78400\n",
      "250/250 [==============================] - 95s 381ms/step - loss: 0.2012 - accuracy: 0.9378 - val_loss: 0.7704 - val_accuracy: 0.7792 - lr: 0.0010\n",
      "Learning rate :  0.001\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.1826 - accuracy: 0.9441\n",
      "Epoch 22: val_accuracy did not improve from 0.78400\n",
      "250/250 [==============================] - 97s 389ms/step - loss: 0.1826 - accuracy: 0.9441 - val_loss: 0.8727 - val_accuracy: 0.7673 - lr: 0.0010\n",
      "Learning rate :  0.001\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.1678 - accuracy: 0.9493\n",
      "Epoch 23: val_accuracy did not improve from 0.78400\n",
      "250/250 [==============================] - 95s 378ms/step - loss: 0.1678 - accuracy: 0.9493 - val_loss: 0.8301 - val_accuracy: 0.7831 - lr: 0.0010\n",
      "Learning rate :  0.001\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.1565 - accuracy: 0.9544\n",
      "Epoch 24: val_accuracy did not improve from 0.78400\n",
      "250/250 [==============================] - 94s 375ms/step - loss: 0.1565 - accuracy: 0.9544 - val_loss: 0.8753 - val_accuracy: 0.7712 - lr: 0.0010\n",
      "Learning rate :  0.001\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.1394 - accuracy: 0.9601\n",
      "Epoch 25: val_accuracy did not improve from 0.78400\n",
      "250/250 [==============================] - 93s 374ms/step - loss: 0.1394 - accuracy: 0.9601 - val_loss: 0.9433 - val_accuracy: 0.7650 - lr: 0.0010\n",
      "Learning rate :  0.001\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.1313 - accuracy: 0.9622\n",
      "Epoch 26: val_accuracy improved from 0.78400 to 0.78770, saving model to C:\\Users\\KOSA\\AI\\saved_models\\cifar10_model-026-0.7877.h5\n",
      "250/250 [==============================] - 97s 389ms/step - loss: 0.1313 - accuracy: 0.9622 - val_loss: 0.8816 - val_accuracy: 0.7877 - lr: 0.0010\n",
      "Learning rate :  0.001\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.1192 - accuracy: 0.9671\n",
      "Epoch 27: val_accuracy improved from 0.78770 to 0.78970, saving model to C:\\Users\\KOSA\\AI\\saved_models\\cifar10_model-027-0.7897.h5\n",
      "250/250 [==============================] - 99s 394ms/step - loss: 0.1192 - accuracy: 0.9671 - val_loss: 0.8756 - val_accuracy: 0.7897 - lr: 0.0010\n",
      "Learning rate :  0.001\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.1104 - accuracy: 0.9691\n",
      "Epoch 28: val_accuracy did not improve from 0.78970\n",
      "250/250 [==============================] - 98s 393ms/step - loss: 0.1104 - accuracy: 0.9691 - val_loss: 0.9422 - val_accuracy: 0.7811 - lr: 0.0010\n",
      "Learning rate :  0.001\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.1063 - accuracy: 0.9710\n",
      "Epoch 29: val_accuracy did not improve from 0.78970\n",
      "250/250 [==============================] - 100s 399ms/step - loss: 0.1063 - accuracy: 0.9710 - val_loss: 1.0261 - val_accuracy: 0.7810 - lr: 0.0010\n",
      "Learning rate :  0.001\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0997 - accuracy: 0.9733\n",
      "Epoch 30: val_accuracy did not improve from 0.78970\n",
      "250/250 [==============================] - 100s 401ms/step - loss: 0.0997 - accuracy: 0.9733 - val_loss: 1.0324 - val_accuracy: 0.7820 - lr: 0.0010\n",
      "Learning rate :  0.001\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0948 - accuracy: 0.9753\n",
      "Epoch 31: val_accuracy did not improve from 0.78970\n",
      "250/250 [==============================] - 99s 398ms/step - loss: 0.0948 - accuracy: 0.9753 - val_loss: 1.0552 - val_accuracy: 0.7765 - lr: 0.0010\n",
      "Learning rate :  0.001\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0854 - accuracy: 0.9783\n",
      "Epoch 32: val_accuracy did not improve from 0.78970\n",
      "250/250 [==============================] - 94s 376ms/step - loss: 0.0854 - accuracy: 0.9783 - val_loss: 1.0597 - val_accuracy: 0.7788 - lr: 0.0010\n",
      "Learning rate :  0.001\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0782 - accuracy: 0.9809\n",
      "Epoch 33: val_accuracy did not improve from 0.78970\n",
      "250/250 [==============================] - 93s 372ms/step - loss: 0.0782 - accuracy: 0.9809 - val_loss: 1.1900 - val_accuracy: 0.7524 - lr: 0.0010\n",
      "Learning rate :  0.001\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0841 - accuracy: 0.9787\n",
      "Epoch 34: val_accuracy did not improve from 0.78970\n",
      "250/250 [==============================] - 91s 365ms/step - loss: 0.0841 - accuracy: 0.9787 - val_loss: 1.1088 - val_accuracy: 0.7731 - lr: 0.0010\n",
      "Learning rate :  0.001\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0789 - accuracy: 0.9804\n",
      "Epoch 35: val_accuracy did not improve from 0.78970\n",
      "250/250 [==============================] - 91s 363ms/step - loss: 0.0789 - accuracy: 0.9804 - val_loss: 1.2759 - val_accuracy: 0.7596 - lr: 0.0010\n",
      "Learning rate :  0.001\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0804 - accuracy: 0.9796\n",
      "Epoch 36: val_accuracy did not improve from 0.78970\n",
      "250/250 [==============================] - 91s 363ms/step - loss: 0.0804 - accuracy: 0.9796 - val_loss: 1.2511 - val_accuracy: 0.7666 - lr: 0.0010\n",
      "Learning rate :  0.001\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0834 - accuracy: 0.9778\n",
      "Epoch 37: val_accuracy did not improve from 0.78970\n",
      "250/250 [==============================] - 91s 364ms/step - loss: 0.0834 - accuracy: 0.9778 - val_loss: 1.1399 - val_accuracy: 0.7804 - lr: 0.0010\n",
      "Learning rate :  0.001\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0727 - accuracy: 0.9824\n",
      "Epoch 38: val_accuracy did not improve from 0.78970\n",
      "250/250 [==============================] - 91s 363ms/step - loss: 0.0727 - accuracy: 0.9824 - val_loss: 1.2435 - val_accuracy: 0.7693 - lr: 0.0010\n",
      "Learning rate :  0.001\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0612 - accuracy: 0.9874\n",
      "Epoch 39: val_accuracy did not improve from 0.78970\n",
      "250/250 [==============================] - 90s 362ms/step - loss: 0.0612 - accuracy: 0.9874 - val_loss: 1.1946 - val_accuracy: 0.7812 - lr: 0.0010\n",
      "Learning rate :  0.001\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0561 - accuracy: 0.9890\n",
      "Epoch 40: val_accuracy did not improve from 0.78970\n",
      "250/250 [==============================] - 91s 363ms/step - loss: 0.0561 - accuracy: 0.9890 - val_loss: 1.3212 - val_accuracy: 0.7674 - lr: 0.0010\n",
      "Learning rate :  0.001\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0706 - accuracy: 0.9833\n",
      "Epoch 41: val_accuracy did not improve from 0.78970\n",
      "250/250 [==============================] - 90s 362ms/step - loss: 0.0706 - accuracy: 0.9833 - val_loss: 1.2271 - val_accuracy: 0.7839 - lr: 0.0010\n",
      "Learning rate :  0.0001\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0353 - accuracy: 0.9969 \n",
      "Epoch 42: val_accuracy improved from 0.78970 to 0.80190, saving model to C:\\Users\\KOSA\\AI\\saved_models\\cifar10_model-042-0.8019.h5\n",
      "250/250 [==============================] - 3456s 14s/step - loss: 0.0353 - accuracy: 0.9969 - val_loss: 1.0861 - val_accuracy: 0.8019 - lr: 1.0000e-04\n",
      "Learning rate :  0.0001\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0265 - accuracy: 0.9997\n",
      "Epoch 43: val_accuracy improved from 0.80190 to 0.80250, saving model to C:\\Users\\KOSA\\AI\\saved_models\\cifar10_model-043-0.8025.h5\n",
      "250/250 [==============================] - 92s 368ms/step - loss: 0.0265 - accuracy: 0.9997 - val_loss: 1.0877 - val_accuracy: 0.8025 - lr: 1.0000e-04\n",
      "Learning rate :  0.0001\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0251 - accuracy: 0.9999\n",
      "Epoch 44: val_accuracy improved from 0.80250 to 0.80410, saving model to C:\\Users\\KOSA\\AI\\saved_models\\cifar10_model-044-0.8041.h5\n",
      "250/250 [==============================] - 90s 359ms/step - loss: 0.0251 - accuracy: 0.9999 - val_loss: 1.0919 - val_accuracy: 0.8041 - lr: 1.0000e-04\n",
      "Learning rate :  0.0001\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0241 - accuracy: 1.0000\n",
      "Epoch 45: val_accuracy improved from 0.80410 to 0.80480, saving model to C:\\Users\\KOSA\\AI\\saved_models\\cifar10_model-045-0.8048.h5\n",
      "250/250 [==============================] - 90s 360ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 1.0976 - val_accuracy: 0.8048 - lr: 1.0000e-04\n",
      "Learning rate :  0.0001\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0235 - accuracy: 0.9999\n",
      "Epoch 46: val_accuracy improved from 0.80480 to 0.80530, saving model to C:\\Users\\KOSA\\AI\\saved_models\\cifar10_model-046-0.8053.h5\n",
      "250/250 [==============================] - 91s 363ms/step - loss: 0.0235 - accuracy: 0.9999 - val_loss: 1.1018 - val_accuracy: 0.8053 - lr: 1.0000e-04\n",
      "Learning rate :  0.0001\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 1.0000\n",
      "Epoch 47: val_accuracy did not improve from 0.80530\n",
      "250/250 [==============================] - 90s 360ms/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 1.1033 - val_accuracy: 0.8045 - lr: 1.0000e-04\n",
      "Learning rate :  0.0001\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0226 - accuracy: 1.0000\n",
      "Epoch 48: val_accuracy improved from 0.80530 to 0.80560, saving model to C:\\Users\\KOSA\\AI\\saved_models\\cifar10_model-048-0.8056.h5\n",
      "250/250 [==============================] - 90s 360ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 1.1064 - val_accuracy: 0.8056 - lr: 1.0000e-04\n",
      "Learning rate :  0.0001\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0223 - accuracy: 1.0000\n",
      "Epoch 49: val_accuracy did not improve from 0.80560\n",
      "250/250 [==============================] - 90s 360ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 1.1152 - val_accuracy: 0.8051 - lr: 1.0000e-04\n",
      "Learning rate :  0.0001\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0218 - accuracy: 1.0000\n",
      "Epoch 50: val_accuracy improved from 0.80560 to 0.80590, saving model to C:\\Users\\KOSA\\AI\\saved_models\\cifar10_model-050-0.8059.h5\n",
      "250/250 [==============================] - 90s 360ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 1.1194 - val_accuracy: 0.8059 - lr: 1.0000e-04\n",
      "Learning rate :  0.0001\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0216 - accuracy: 1.0000\n",
      "Epoch 51: val_accuracy improved from 0.80590 to 0.80600, saving model to C:\\Users\\KOSA\\AI\\saved_models\\cifar10_model-051-0.8060.h5\n",
      "250/250 [==============================] - 92s 366ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 1.1189 - val_accuracy: 0.8060 - lr: 1.0000e-04\n",
      "Learning rate :  0.0001\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 1.0000\n",
      "Epoch 52: val_accuracy did not improve from 0.80600\n",
      "250/250 [==============================] - 97s 386ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 1.1226 - val_accuracy: 0.8049 - lr: 1.0000e-04\n",
      "Learning rate :  0.0001\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0207 - accuracy: 1.0000\n",
      "Epoch 53: val_accuracy did not improve from 0.80600\n",
      "250/250 [==============================] - 93s 372ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 1.1283 - val_accuracy: 0.8054 - lr: 1.0000e-04\n",
      "Learning rate :  0.0001\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 1.0000\n",
      "Epoch 54: val_accuracy improved from 0.80600 to 0.80630, saving model to C:\\Users\\KOSA\\AI\\saved_models\\cifar10_model-054-0.8063.h5\n",
      "250/250 [==============================] - 92s 368ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 1.1251 - val_accuracy: 0.8063 - lr: 1.0000e-04\n",
      "Learning rate :  0.0001\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 1.0000\n",
      "Epoch 55: val_accuracy improved from 0.80630 to 0.80740, saving model to C:\\Users\\KOSA\\AI\\saved_models\\cifar10_model-055-0.8074.h5\n",
      "250/250 [==============================] - 92s 368ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 1.1335 - val_accuracy: 0.8074 - lr: 1.0000e-04\n",
      "Learning rate :  0.0001\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 1.0000\n",
      "Epoch 56: val_accuracy did not improve from 0.80740\n",
      "250/250 [==============================] - 93s 372ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 1.1443 - val_accuracy: 0.8056 - lr: 1.0000e-04\n",
      "Learning rate :  0.0001\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0192 - accuracy: 1.0000\n",
      "Epoch 57: val_accuracy did not improve from 0.80740\n",
      "250/250 [==============================] - 99s 394ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 1.1442 - val_accuracy: 0.8061 - lr: 1.0000e-04\n",
      "Learning rate :  0.0001\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 1.0000\n",
      "Epoch 58: val_accuracy did not improve from 0.80740\n",
      "250/250 [==============================] - 95s 382ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 1.1533 - val_accuracy: 0.8064 - lr: 1.0000e-04\n",
      "Learning rate :  0.0001\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0184 - accuracy: 1.0000\n",
      "Epoch 59: val_accuracy improved from 0.80740 to 0.80750, saving model to C:\\Users\\KOSA\\AI\\saved_models\\cifar10_model-059-0.8075.h5\n",
      "250/250 [==============================] - 94s 378ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 1.1552 - val_accuracy: 0.8075 - lr: 1.0000e-04\n",
      "Learning rate :  0.0001\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0179 - accuracy: 1.0000\n",
      "Epoch 60: val_accuracy did not improve from 0.80750\n",
      "250/250 [==============================] - 96s 382ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 1.1578 - val_accuracy: 0.8060 - lr: 1.0000e-04\n",
      "Learning rate :  0.0001\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 1.0000\n",
      "Epoch 61: val_accuracy improved from 0.80750 to 0.80760, saving model to C:\\Users\\KOSA\\AI\\saved_models\\cifar10_model-061-0.8076.h5\n",
      "250/250 [==============================] - 93s 372ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 1.1582 - val_accuracy: 0.8076 - lr: 1.0000e-04\n",
      "Learning rate :  1e-05\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 1.0000\n",
      "Epoch 62: val_accuracy did not improve from 0.80760\n",
      "250/250 [==============================] - 93s 371ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 1.1678 - val_accuracy: 0.8071 - lr: 1.0000e-05\n",
      "Learning rate :  1e-05\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 1.0000\n",
      "Epoch 63: val_accuracy improved from 0.80760 to 0.80840, saving model to C:\\Users\\KOSA\\AI\\saved_models\\cifar10_model-063-0.8084.h5\n",
      "250/250 [==============================] - 97s 388ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 1.1706 - val_accuracy: 0.8084 - lr: 1.0000e-05\n",
      "Learning rate :  1e-05\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 1.0000\n",
      "Epoch 64: val_accuracy did not improve from 0.80840\n",
      "250/250 [==============================] - 94s 377ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 1.1712 - val_accuracy: 0.8079 - lr: 1.0000e-05\n",
      "Learning rate :  1e-05\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 1.0000\n",
      "Epoch 65: val_accuracy did not improve from 0.80840\n",
      "250/250 [==============================] - 96s 384ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 1.1725 - val_accuracy: 0.8075 - lr: 1.0000e-05\n",
      "Learning rate :  1e-05\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0167 - accuracy: 1.0000\n",
      "Epoch 66: val_accuracy did not improve from 0.80840\n",
      "250/250 [==============================] - 96s 386ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 1.1725 - val_accuracy: 0.8080 - lr: 1.0000e-05\n",
      "Learning rate :  1e-05\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0166 - accuracy: 1.0000\n",
      "Epoch 67: val_accuracy did not improve from 0.80840\n",
      "250/250 [==============================] - 96s 386ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 1.1741 - val_accuracy: 0.8079 - lr: 1.0000e-05\n",
      "Learning rate :  1e-05\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0165 - accuracy: 1.0000\n",
      "Epoch 68: val_accuracy did not improve from 0.80840\n",
      "250/250 [==============================] - 96s 384ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 1.1750 - val_accuracy: 0.8083 - lr: 1.0000e-05\n",
      "Learning rate :  1e-05\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0165 - accuracy: 1.0000\n",
      "Epoch 69: val_accuracy did not improve from 0.80840\n",
      "250/250 [==============================] - 101s 406ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 1.1755 - val_accuracy: 0.8079 - lr: 1.0000e-05\n",
      "Learning rate :  1e-05\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 1.0000\n",
      "Epoch 70: val_accuracy did not improve from 0.80840\n",
      "250/250 [==============================] - 98s 393ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 1.1775 - val_accuracy: 0.8071 - lr: 1.0000e-05\n",
      "Learning rate :  1e-05\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 1.0000\n",
      "Epoch 71: val_accuracy did not improve from 0.80840\n",
      "250/250 [==============================] - 94s 377ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 1.1811 - val_accuracy: 0.8068 - lr: 1.0000e-05\n",
      "Learning rate :  1e-05\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0162 - accuracy: 1.0000\n",
      "Epoch 72: val_accuracy did not improve from 0.80840\n",
      "250/250 [==============================] - 96s 383ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 1.1806 - val_accuracy: 0.8067 - lr: 1.0000e-05\n",
      "Learning rate :  1e-05\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0161 - accuracy: 1.0000\n",
      "Epoch 73: val_accuracy did not improve from 0.80840\n",
      "250/250 [==============================] - 96s 383ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 1.1840 - val_accuracy: 0.8072 - lr: 1.0000e-05\n",
      "Learning rate :  1e-05\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0161 - accuracy: 1.0000\n",
      "Epoch 74: val_accuracy did not improve from 0.80840\n",
      "250/250 [==============================] - 97s 387ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 1.1824 - val_accuracy: 0.8073 - lr: 1.0000e-05\n",
      "Learning rate :  1e-05\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 1.0000\n",
      "Epoch 75: val_accuracy did not improve from 0.80840\n",
      "250/250 [==============================] - 94s 377ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 1.1852 - val_accuracy: 0.8077 - lr: 1.0000e-05\n",
      "Learning rate :  1e-05\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0158 - accuracy: 1.0000\n",
      "Epoch 76: val_accuracy did not improve from 0.80840\n",
      "250/250 [==============================] - 97s 390ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 1.1844 - val_accuracy: 0.8069 - lr: 1.0000e-05\n",
      "Learning rate :  1e-05\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 1.0000\n",
      "Epoch 77: val_accuracy did not improve from 0.80840\n",
      "250/250 [==============================] - 93s 374ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 1.1863 - val_accuracy: 0.8061 - lr: 1.0000e-05\n",
      "Learning rate :  1e-05\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0156 - accuracy: 1.0000\n",
      "Epoch 78: val_accuracy did not improve from 0.80840\n",
      "250/250 [==============================] - 94s 376ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 1.1884 - val_accuracy: 0.8072 - lr: 1.0000e-05\n",
      "Learning rate :  1e-05\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 1.0000\n",
      "Epoch 79: val_accuracy did not improve from 0.80840\n",
      "250/250 [==============================] - 93s 370ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 1.1920 - val_accuracy: 0.8074 - lr: 1.0000e-05\n",
      "Learning rate :  1e-05\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 1.0000\n",
      "Epoch 80: val_accuracy did not improve from 0.80840\n",
      "250/250 [==============================] - 92s 368ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 1.1899 - val_accuracy: 0.8076 - lr: 1.0000e-05\n",
      "Learning rate :  1e-05\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 1.0000\n",
      "Epoch 81: val_accuracy did not improve from 0.80840\n",
      "250/250 [==============================] - 95s 382ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 1.1923 - val_accuracy: 0.8076 - lr: 1.0000e-05\n",
      "Learning rate :  1e-06\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 82: val_accuracy did not improve from 0.80840\n",
      "250/250 [==============================] - 95s 378ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 1.1939 - val_accuracy: 0.8070 - lr: 1.0000e-06\n",
      "Learning rate :  1e-06\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 83: val_accuracy did not improve from 0.80840\n",
      "250/250 [==============================] - 95s 380ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 1.1947 - val_accuracy: 0.8069 - lr: 1.0000e-06\n",
      "Learning rate :  1e-06\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 84: val_accuracy did not improve from 0.80840\n",
      "250/250 [==============================] - 95s 382ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 1.1952 - val_accuracy: 0.8075 - lr: 1.0000e-06\n",
      "Learning rate :  1e-06\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 85: val_accuracy did not improve from 0.80840\n",
      "250/250 [==============================] - 93s 373ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 1.1945 - val_accuracy: 0.8072 - lr: 1.0000e-06\n",
      "Learning rate :  1e-06\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 86: val_accuracy did not improve from 0.80840\n",
      "250/250 [==============================] - 92s 369ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 1.1952 - val_accuracy: 0.8069 - lr: 1.0000e-06\n",
      "Learning rate :  1e-06\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 87: val_accuracy did not improve from 0.80840\n",
      "250/250 [==============================] - 93s 372ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 1.1953 - val_accuracy: 0.8068 - lr: 1.0000e-06\n",
      "Learning rate :  1e-06\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 88: val_accuracy did not improve from 0.80840\n",
      "250/250 [==============================] - 93s 372ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 1.1958 - val_accuracy: 0.8066 - lr: 1.0000e-06\n",
      "Learning rate :  1e-06\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 1.0000\n",
      "Epoch 89: val_accuracy did not improve from 0.80840\n",
      "250/250 [==============================] - 93s 370ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 1.1960 - val_accuracy: 0.8068 - lr: 1.0000e-06\n",
      "Learning rate :  1e-06\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 1.0000\n",
      "Epoch 90: val_accuracy did not improve from 0.80840\n",
      "250/250 [==============================] - 93s 370ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 1.1967 - val_accuracy: 0.8071 - lr: 1.0000e-06\n",
      "Learning rate :  1e-06\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 1.0000\n",
      "Epoch 91: val_accuracy did not improve from 0.80840\n",
      "250/250 [==============================] - 96s 384ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 1.1955 - val_accuracy: 0.8069 - lr: 1.0000e-06\n",
      "Learning rate :  5e-07\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 1.0000\n",
      "Epoch 92: val_accuracy did not improve from 0.80840\n",
      "250/250 [==============================] - 91s 364ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 1.1962 - val_accuracy: 0.8068 - lr: 5.0000e-07\n",
      "Learning rate :  5e-07\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 1.0000\n",
      "Epoch 93: val_accuracy did not improve from 0.80840\n",
      "250/250 [==============================] - 91s 364ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 1.1970 - val_accuracy: 0.8068 - lr: 5.0000e-07\n",
      "Learning rate :  5e-07\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 1.0000\n",
      "Epoch 94: val_accuracy did not improve from 0.80840\n",
      "250/250 [==============================] - 91s 364ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 1.1967 - val_accuracy: 0.8068 - lr: 5.0000e-07\n",
      "Learning rate :  5e-07\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 1.0000\n",
      "Epoch 95: val_accuracy did not improve from 0.80840\n",
      "250/250 [==============================] - 91s 363ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 1.1969 - val_accuracy: 0.8071 - lr: 5.0000e-07\n",
      "Learning rate :  5e-07\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 1.0000\n",
      "Epoch 96: val_accuracy did not improve from 0.80840\n",
      "250/250 [==============================] - 96s 385ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 1.1975 - val_accuracy: 0.8069 - lr: 5.0000e-07\n",
      "Learning rate :  5e-07\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 1.0000\n",
      "Epoch 97: val_accuracy did not improve from 0.80840\n",
      "250/250 [==============================] - 94s 374ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 1.1971 - val_accuracy: 0.8069 - lr: 5.0000e-07\n",
      "Learning rate :  5e-07\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 1.0000\n",
      "Epoch 98: val_accuracy did not improve from 0.80840\n",
      "250/250 [==============================] - 91s 365ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 1.1975 - val_accuracy: 0.8063 - lr: 5.0000e-07\n",
      "Learning rate :  5e-07\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 1.0000\n",
      "Epoch 99: val_accuracy did not improve from 0.80840\n",
      "250/250 [==============================] - 91s 365ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 1.1967 - val_accuracy: 0.8064 - lr: 5.0000e-07\n",
      "Learning rate :  5e-07\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 1.0000\n",
      "Epoch 100: val_accuracy did not improve from 0.80840\n",
      "250/250 [==============================] - 91s 365ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 1.1977 - val_accuracy: 0.8067 - lr: 5.0000e-07\n"
     ]
    }
   ],
   "source": [
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "my_callbacks = [checkpoint, lr_scheduler]\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=Adam(), metrics=[\"accuracy\"])\n",
    "history = model.fit(train_X, train_y, validation_data=(test_X, test_y), epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dddff5a-8325-4f57-a3e2-32e30926d5dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.14",
   "language": "python",
   "name": "tf2.14"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
